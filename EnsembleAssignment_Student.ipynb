{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# AirBnB guest arrival prediction using tree-based methods\n\n\n\n<b><div style=\"text-align: right\">[TOTAL POINTS: 9]</div></b>\n\nThe assignment is divided into three different levels: Level1, Level2, and Level3.\n\n## Learning Objective(Level 1)\n\n<b><div style=\"text-align: right\">[POINTS: 4]</div></b>\n\nBy the end of this assignment, a student should be able to\n\n- Apply necessary preprocessing steps on the data to make it suitable for training.\n\n- Train Bagging Classifier, Random Forest Classifier, XGBoost Classifier.\n\n- Fine-tune and monitor the performance of XGBoost.\n\n\n\nLet's start with the problem description of level1.\nIn this assignment, you will train different ensemble models to predict whether the customer will cancel the booking or not. For a tourism-based country like Nepal, hospitality is a major source of income. The given data represents booking information made by foreign customers via AirBnB for the year 2018. Your task in level1 is to use this data to predict whether the customer will cancel the booking or not.\n","metadata":{"deletable":false,"id":"2PO8PExZwsGd","nbgrader":{"cell_type":"markdown","checksum":"f7f8a87a9f6db06c8e8b8a128d575484","grade":false,"grade_id":"cell-07f7a8784a17e6a5","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"markdown","source":"## Dataset Description:\n\nThe dataset, **AirBnB customer arrival prediction**, contains information regarding booking in the hotel, and includes features like such as meal, arrival date(date of booking), car parking space in hotel, etc. All features are listed below.\n\nNote: The given dataset is a modification of [Hotel booking demand datasets](https://www.sciencedirect.com/science/article/pii/S2352340918315191) collected by **Nuano et al.** and is availabe under [Creative Commons 4.0](https://creativecommons.org/licenses/by/4.0/).\n\n**Number of Instances:** 119,386 \\\n**Number of Attributes:** 25 **Input Features** + 1 **Target**(__is_canceled__)\n\n### Attribute Information:\nThe detail information of each attribute is listed as:\n\n* **hotel** - Type of hotel resort or city\n* **is_canceled** - The label column. This indicates whether the guests canceled their booking or they checked-in\n* **lead_time** - Number of days that elapsed between the entering date of the booking into the PMS and the arrival date\n* **arrival_date_year** - year of the arrival date\n* **arrival_date_month** - Month of arrival date with 12 categories: “January” to “December” expressed in numbers. 1 indicates January, and 12 indicate December. \n* **arrival_date_week_number** - Week number of the arrival date\n* **arrival_date_day_of_month** - Day of the month of the arrival date\n* **stays_in_weekend_nights** - Number of weekend nights (Saturday or Sunday) the guest stayed or booked to stay at the hotel.\n* **stays_in_week_nights** - Number of week nights (Monday to Friday) the guest stayed or booked to stay at the hotel\n* **meal** - Type of meal booked. \n* **country** - Country of origin. Categories are represented in the ISO 3155–3:2013 format\n* **market_segment** - Market segment designation. In categories, the term \"TA\" means \"Travel Agents\" and \"TO\" means \"Tour Operators\"\n* **distribution_channel** - Booking distribution channel. The term \"TA\" means \"Travel Agents\" and \"TO\" means \"Tour Operators\"\n* **is_repeated_guest** - Value indicating if the booking name was from a repeated guest (1) or not (0)\n* **reserved_room_type** - Code of room type reserved. \n* **assigned_room_type** - Code for the type of room assigned to the booking. Sometimes the assigned room type differs from the reserved room type due to hotel operation reasons (e.g., overbooking) or by customer request.\n* **booking_changes** - Number of changes/amendments made to the booking from the moment the booking was entered on the PMS until the moment of check-in or cancellation\n* **deposit_type** - Indication on if the customer deposited to guarantee the booking.\n* **agent** - ID of the travel agency that made the booking\n* **days_in_waiting_list** - Number of days the booking was on the waiting list before it was confirmed to the customer. \n* **customer_type** - Type of booking. One of Contract, Group, Transient, and Transient-party.\n* **adr** - Average Daily Rate\n* **required_car_parking_spaces** - Number of car parking spaces required by the customer.\n* **total_of_special_requests** - Number of special requests made by the customer (e.g. twin bed or high floor)\n* **total_guests** - Total number of guests(includes adults, children, and babies)\n* **net_booking_cancelled** - A difference between the total number of the previous booking canceled and the previous booking not canceled before this booking. A positive value means that the customer did not cancel most of the previous booking.","metadata":{"deletable":false,"id":"Epa9-UlFwsGi","nbgrader":{"cell_type":"markdown","checksum":"0294ba34b6949a3460fc5f3e395bbbc1","grade":false,"grade_id":"cell-efbfcf6cef60da2e","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"markdown","source":"### Import libraries","metadata":{"deletable":false,"id":"VssZ8Kf_wsGm","nbgrader":{"cell_type":"markdown","checksum":"a2e702129c88a9379910c3afba966c44","grade":false,"grade_id":"cell-1376b6668cc0b7e3","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport pickle\nfrom matplotlib import pyplot as plt\n\nRANDOM_STATE = 7\nnp.random.seed(RANDOM_STATE)","metadata":{"deletable":false,"id":"XM9q2-0ZwsGp","nbgrader":{"cell_type":"code","checksum":"e7dabe83fb818c087ddde93f145acc34","grade":false,"grade_id":"cell-8aaadd6d8208e92f","locked":true,"schema_version":3,"solution":false,"task":false},"execution":{"iopub.status.busy":"2022-06-25T11:36:05.736341Z","iopub.execute_input":"2022-06-25T11:36:05.736815Z","iopub.status.idle":"2022-06-25T11:36:05.765107Z","shell.execute_reply.started":"2022-06-25T11:36:05.736714Z","shell.execute_reply":"2022-06-25T11:36:05.763986Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### Load csv file","metadata":{"deletable":false,"id":"pEDgsWu_wsG5","nbgrader":{"cell_type":"markdown","checksum":"280a979d45c3059ea2bf611656cd6a99","grade":false,"grade_id":"cell-24b969ae9447e0d8","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"code","source":"df= pd.read_csv(\"https://drive.google.com/uc?id=1Gqk7mPLeXlx7mo8iQZM0TpcNmnyFa-LD\", index_col = 0)\ndf.head()","metadata":{"deletable":false,"id":"_ELsyzGxwsG7","nbgrader":{"cell_type":"code","checksum":"e15e679f7b304b91742b0bfa20c904b2","grade":false,"grade_id":"cell-e94bfbaf67531051","locked":true,"schema_version":3,"solution":false,"task":false},"execution":{"iopub.status.busy":"2022-06-25T11:36:05.766406Z","iopub.execute_input":"2022-06-25T11:36:05.767320Z","iopub.status.idle":"2022-06-25T11:36:09.699993Z","shell.execute_reply.started":"2022-06-25T11:36:05.767281Z","shell.execute_reply":"2022-06-25T11:36:09.698856Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing\n### Identification of features with missing values\nLet's find out if the columns in our dataset has any misssing values.","metadata":{"deletable":false,"id":"-PYR9djVwsHG","nbgrader":{"cell_type":"markdown","checksum":"4bc860d3d7d42438946fd99db9f763cf","grade":false,"grade_id":"cell-6b18126a4854d153","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"deletable":false,"id":"Rkd1RjvSwsHI","nbgrader":{"cell_type":"code","checksum":"896555bd445bdf2270f179fbb7ca552b","grade":false,"grade_id":"cell-b4b33f9f363968d7","locked":true,"schema_version":3,"solution":false,"task":false},"execution":{"iopub.status.busy":"2022-06-25T11:36:09.702472Z","iopub.execute_input":"2022-06-25T11:36:09.703261Z","iopub.status.idle":"2022-06-25T11:36:09.787589Z","shell.execute_reply.started":"2022-06-25T11:36:09.703218Z","shell.execute_reply":"2022-06-25T11:36:09.786473Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"We can see that columns `agent`, `assigned_room_type`, `distribution_channel`, `meal`, `country`, and `total_guests` have missing values.\n\nSince only four instances in the column `total_guests` have missing value, we will drop them.","metadata":{"deletable":false,"id":"oY3mhFEOwsHQ","nbgrader":{"cell_type":"markdown","checksum":"c39d55a079531160aae79f50afaef532","grade":false,"grade_id":"cell-0fa66ac9d0129824","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"code","source":"# removing all rows that have missing values in total_guests column\ndf.dropna(how='any', subset=['total_guests'], inplace=True)","metadata":{"deletable":false,"id":"UKdOTd4BwsHS","nbgrader":{"cell_type":"code","checksum":"49e452cee1b383d62a1d14b544bba2ba","grade":false,"grade_id":"cell-0658ae9dff5838f4","locked":true,"schema_version":3,"solution":false,"task":false},"execution":{"iopub.status.busy":"2022-06-25T11:36:09.789254Z","iopub.execute_input":"2022-06-25T11:36:09.790283Z","iopub.status.idle":"2022-06-25T11:36:09.817705Z","shell.execute_reply.started":"2022-06-25T11:36:09.790237Z","shell.execute_reply":"2022-06-25T11:36:09.816720Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"We will impute rest of the features with mode.","metadata":{"deletable":false,"id":"85mnhFDXwsHb","nbgrader":{"cell_type":"markdown","checksum":"b3e70ed8cb44ea86286e0bb2f2b94eaa","grade":false,"grade_id":"cell-86c773ad37636294","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"code","source":"missing_features = ['agent', 'assigned_room_type', 'distribution_channel', 'meal', 'country']\nfor feature in missing_features:\n    df[feature].fillna(df[feature].mode()[0], inplace = True)","metadata":{"deletable":false,"id":"WVSifF4qwsHc","nbgrader":{"cell_type":"code","checksum":"6fe2fceeabaef5f62ae778a602220393","grade":false,"grade_id":"cell-ba231c76e63aebc1","locked":true,"schema_version":3,"solution":false,"task":false},"execution":{"iopub.status.busy":"2022-06-25T11:36:09.823966Z","iopub.execute_input":"2022-06-25T11:36:09.824808Z","iopub.status.idle":"2022-06-25T11:36:09.914201Z","shell.execute_reply.started":"2022-06-25T11:36:09.824770Z","shell.execute_reply":"2022-06-25T11:36:09.913185Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Until now, we have imputed all the missing values in the dataset.","metadata":{"deletable":false,"id":"RQEJ1XRCwsHl","nbgrader":{"cell_type":"markdown","checksum":"7b43801791a6abda95427849b1cb91f4","grade":false,"grade_id":"cell-9c70daa05ee0fc45","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"markdown","source":"### Feature generation\n\nHere we will combine features `arrival_date_month` and `arrival_date_year` to generate a new feature `month`.","metadata":{"deletable":false,"id":"LYANbhhZwsHm","nbgrader":{"cell_type":"markdown","checksum":"3f8026d7b6b2e60abf945d927cab6633","grade":false,"grade_id":"cell-034cdf27d4021ee4","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"code","source":"df['arrival_date_year'].unique()","metadata":{"deletable":false,"id":"AeWZtrUJwsHn","nbgrader":{"cell_type":"code","checksum":"557e53c67c54549b885d7ed1e90a54bd","grade":false,"grade_id":"cell-b608b12ac2d9d2d4","locked":true,"schema_version":3,"solution":false,"task":false},"execution":{"iopub.status.busy":"2022-06-25T11:36:09.915758Z","iopub.execute_input":"2022-06-25T11:36:09.916426Z","iopub.status.idle":"2022-06-25T11:36:09.926388Z","shell.execute_reply.started":"2022-06-25T11:36:09.916382Z","shell.execute_reply":"2022-06-25T11:36:09.925056Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df['arrival_date_month'].unique()","metadata":{"deletable":false,"id":"_ZXwBZH7wsHu","nbgrader":{"cell_type":"code","checksum":"b31f68ddbd785907bdd27c4bae7b2ecc","grade":false,"grade_id":"cell-af60eb808bab599d","locked":true,"schema_version":3,"solution":false,"task":false},"execution":{"iopub.status.busy":"2022-06-25T11:36:09.927712Z","iopub.execute_input":"2022-06-25T11:36:09.928703Z","iopub.status.idle":"2022-06-25T11:36:09.945853Z","shell.execute_reply.started":"2022-06-25T11:36:09.928669Z","shell.execute_reply":"2022-06-25T11:36:09.944697Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"In the feature `month`,  we will consider Jan, 2015 as 0, Feb, 2015 as 1, and so on. So this feature will represent the month number starting from Jan, 2015.","metadata":{"deletable":false,"id":"dIPIGG8LwsH1","nbgrader":{"cell_type":"markdown","checksum":"c3e7241f95749484f760cfc99e757e00","grade":false,"grade_id":"cell-40928221e2b7bd58","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"code","source":"replace_year = {2015:0, 2016: 12, 2017:24}\nreplace_month= {'Januray':0, 'February': 1, 'March': 2, 'April': 3, 'May': 4, 'June': 5, 'July': 6, 'August': 7, 'September': 8, 'October': 9, 'November': 10, 'December': 11}","metadata":{"deletable":false,"id":"beVp5g3ZwsH2","nbgrader":{"cell_type":"code","checksum":"249e679b563812bbdbe2b0fd033e40e3","grade":false,"grade_id":"cell-dad3284a72cc9d72","locked":true,"schema_version":3,"solution":false,"task":false},"execution":{"iopub.status.busy":"2022-06-25T11:36:09.947354Z","iopub.execute_input":"2022-06-25T11:36:09.947863Z","iopub.status.idle":"2022-06-25T11:36:09.952256Z","shell.execute_reply.started":"2022-06-25T11:36:09.947833Z","shell.execute_reply":"2022-06-25T11:36:09.951466Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df['arrival_date_year'] = df['arrival_date_year'].replace(replace_year)\ndf['arrival_date_month'] = df['arrival_date_month'].replace(replace_month)\ndf['month'] = df['arrival_date_year']+df['arrival_date_year']\n# df.drop(['arrival_date_year', 'arrival_date_year'], axis = 1, inplace = True)\ndf.head()","metadata":{"deletable":false,"id":"L3Q3b4atwsH9","nbgrader":{"cell_type":"code","checksum":"d5f0637933f570a0c6abae6a78c18ed8","grade":false,"grade_id":"cell-d6b991b3165c322e","locked":true,"schema_version":3,"solution":false,"task":false},"execution":{"iopub.status.busy":"2022-06-25T11:36:09.953352Z","iopub.execute_input":"2022-06-25T11:36:09.953828Z","iopub.status.idle":"2022-06-25T11:36:10.029950Z","shell.execute_reply.started":"2022-06-25T11:36:09.953800Z","shell.execute_reply":"2022-06-25T11:36:10.028914Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### Label Encoding\n\nAll categorical features are encoded with label encoding.\n","metadata":{"deletable":false,"id":"-MNF119rwsIC","nbgrader":{"cell_type":"markdown","checksum":"fe14669c48888decd3156cfc53b3f4cc","grade":false,"grade_id":"cell-0c38f70723ae519e","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n\ncat_vars = [var for var in df.columns if df[var].dtypes=='O']\ndf[cat_vars] = df[cat_vars].astype(str).apply(LabelEncoder().fit_transform)\ndf.head()","metadata":{"deletable":false,"id":"sMblbXeEwsIE","nbgrader":{"cell_type":"code","checksum":"28b35d6bc8a3c03d012a1f9536ddc682","grade":false,"grade_id":"cell-ebe3b5cf96137618","locked":true,"schema_version":3,"solution":false,"task":false},"execution":{"iopub.status.busy":"2022-06-25T11:36:10.031292Z","iopub.execute_input":"2022-06-25T11:36:10.031656Z","iopub.status.idle":"2022-06-25T11:36:11.329105Z","shell.execute_reply.started":"2022-06-25T11:36:10.031625Z","shell.execute_reply":"2022-06-25T11:36:11.327495Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"### Train-Test Split\n\nBefore performing train-test split let's check the class distribution.","metadata":{"deletable":false,"id":"3gv7QJLkwsIN","nbgrader":{"cell_type":"markdown","checksum":"45ec4911f01801f503262ad6cde95120","grade":false,"grade_id":"cell-63009ab9120d68aa","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"code","source":"df['is_canceled'].value_counts().plot(kind = 'bar')","metadata":{"deletable":false,"id":"YPhv7xg2wsIO","nbgrader":{"cell_type":"code","checksum":"fc81b76594175d04d9ffb5a8093043b3","grade":false,"grade_id":"cell-4c3c82852baf6e8c","locked":true,"schema_version":3,"solution":false,"task":false},"execution":{"iopub.status.busy":"2022-06-25T11:36:11.333197Z","iopub.execute_input":"2022-06-25T11:36:11.333674Z","iopub.status.idle":"2022-06-25T11:36:11.572000Z","shell.execute_reply.started":"2022-06-25T11:36:11.333629Z","shell.execute_reply":"2022-06-25T11:36:11.571137Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"We see that the dataset is imbalanced. This forces us to:\n- Set `stratify` to `y` while splitting the dataset so that the proportion of `is_canceled = 0`, and `is_canceled = 1` remains constant in the training and test dataset.\n- Use metric like f1 score to assess the performance of our model","metadata":{"deletable":false,"id":"idp18pfRwsIW","nbgrader":{"cell_type":"markdown","checksum":"b48bb06128c0bb670a337fc1bb203d56","grade":false,"grade_id":"cell-13717f78e9b4e741","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n\nRANDOM_STATE = 7\ny= df['is_canceled']\nX = df.drop('is_canceled', axis = 1)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify = y, random_state = RANDOM_STATE)","metadata":{"deletable":false,"id":"ioN2runWwsIX","nbgrader":{"cell_type":"code","checksum":"b7731b5f441ff773a3ba118574999408","grade":false,"grade_id":"cell-8684ac95ede2a433","locked":true,"schema_version":3,"solution":false,"task":false},"execution":{"iopub.status.busy":"2022-06-25T11:36:11.574181Z","iopub.execute_input":"2022-06-25T11:36:11.575101Z","iopub.status.idle":"2022-06-25T11:36:11.775091Z","shell.execute_reply.started":"2022-06-25T11:36:11.575065Z","shell.execute_reply":"2022-06-25T11:36:11.773931Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Bagging\n\n### Exercise 1: Training Bagging Classifier\n<b><div style=\"text-align: right\">[POINTS: 1]</div></b>\n\n---\n\n\n**Task:** \n-  Instantiate BaggingClassifier in the variable `bagging` with __n_estimators__ set to 100 and  __random_state__ set to RANDOM_STATE","metadata":{"deletable":false,"id":"-FH86C_ewsId","nbgrader":{"cell_type":"markdown","checksum":"bba3e1a34b7691d8619eae1ec4ebbcdd","grade":false,"grade_id":"cell-905fcb117aad61f6","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"code","source":"### Ex-1-Task-1\n\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.metrics import f1_score\n\n\nbagging = None\n### BEGIN SOLUTION\nbagging = BaggingClassifier(n_estimators = 100, random_state = RANDOM_STATE)\n# your code here\n### END SOLUTION\nbagging.fit(X_train, y_train)\nprint(\"Train f1_score:\", f1_score(y_train, bagging.predict(X_train), average = 'weighted'))\nprint(\"Test f1_score:\", f1_score(y_test, bagging.predict(X_test), average = 'weighted'))","metadata":{"deletable":false,"id":"v4WnJLOCwsIe","nbgrader":{"cell_type":"code","checksum":"390823431cb81a65a7c86e05f1c9a504","grade":false,"grade_id":"cell-b035578ba9f37360","locked":false,"schema_version":3,"solution":true,"task":false},"tags":["Ex-1-Task-1"],"execution":{"iopub.status.busy":"2022-06-25T11:36:11.776414Z","iopub.execute_input":"2022-06-25T11:36:11.776788Z","iopub.status.idle":"2022-06-25T11:37:11.773378Z","shell.execute_reply.started":"2022-06-25T11:36:11.776755Z","shell.execute_reply":"2022-06-25T11:37:11.772014Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"assert bagging is not None","metadata":{"deletable":false,"id":"pTrHUGX7wsIm","nbgrader":{"cell_type":"code","checksum":"7b4cc6939d96357b820d35147109a930","grade":true,"grade_id":"cell-4abb817fcb9f3fd8","locked":true,"points":1,"schema_version":3,"solution":false,"task":false},"tags":["Ex-1-Task-1"],"execution":{"iopub.status.busy":"2022-06-25T11:37:11.774833Z","iopub.execute_input":"2022-06-25T11:37:11.775330Z","iopub.status.idle":"2022-06-25T11:37:11.780875Z","shell.execute_reply.started":"2022-06-25T11:37:11.775296Z","shell.execute_reply":"2022-06-25T11:37:11.779589Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Random Forest\n\n### Exercise 2: Training Random Forest Classifier\n<b><div style=\"text-align: right\">[POINTS: 1]</div></b>\n\n---\n\n\n**Task:** \n-  Instantiate RandomForestClassifier in the variable `rf` with __n_estimators__ set to 100, and  __random_state__ set to RANDOM_STATE","metadata":{"deletable":false,"id":"7aoaNQUYwsIs","nbgrader":{"cell_type":"markdown","checksum":"10fca3d9fe7aa9fbffdea39306d3a84d","grade":false,"grade_id":"cell-93661e0a4d78d9c6","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"code","source":"### Ex-2-Task-1\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf = None\n### BEGIN SOLUTION\n# your code here\nrf = RandomForestClassifier(n_estimators = 100, random_state = RANDOM_STATE)\n### END SOLUTION\nrf.fit(X_train, y_train)\nprint(\"Train f1_score:\", f1_score(y_train, rf.predict(X_train), average = 'weighted'))\nprint(\"Test f1_score:\", f1_score(y_test, rf.predict(X_test), average = 'weighted'))","metadata":{"deletable":false,"id":"6XDrmqnkwsIt","nbgrader":{"cell_type":"code","checksum":"91595f945ef5796a71208ccae3b2e21b","grade":false,"grade_id":"cell-495dd9906e2fa3a6","locked":false,"schema_version":3,"solution":true,"task":false},"tags":["Ex-2-Task-1"],"execution":{"iopub.status.busy":"2022-06-25T11:37:11.782294Z","iopub.execute_input":"2022-06-25T11:37:11.782616Z","iopub.status.idle":"2022-06-25T11:37:29.256458Z","shell.execute_reply.started":"2022-06-25T11:37:11.782587Z","shell.execute_reply":"2022-06-25T11:37:29.255050Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"assert rf is not None","metadata":{"deletable":false,"id":"SuRcc3LHwsIy","nbgrader":{"cell_type":"code","checksum":"965b6177c8fc27e520ff4ae242ce348d","grade":true,"grade_id":"cell-2cbd41b766162a73","locked":true,"points":1,"schema_version":3,"solution":false,"task":false},"tags":["Ex-2-Task-1"],"execution":{"iopub.status.busy":"2022-06-25T11:37:29.257989Z","iopub.execute_input":"2022-06-25T11:37:29.258336Z","iopub.status.idle":"2022-06-25T11:37:29.263530Z","shell.execute_reply.started":"2022-06-25T11:37:29.258304Z","shell.execute_reply":"2022-06-25T11:37:29.262302Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"## XGBoost\n\n### Exercise 3: XGBoost Training\n<b><div style=\"text-align: right\">[POINTS: 1]</div></b>\n\n---\nHere we will train XGBoost with most of the parameters left to default.\n\n**Task:** \n-  Instantiate XGBClassifier in the variable `xgb` with __n_estimators__ set to 100 and __random_state__ set to RANDOM_STATE\n","metadata":{"deletable":false,"id":"HrCu3Pp-wsI5","nbgrader":{"cell_type":"markdown","checksum":"ceea308dac698346faf96641653f5648","grade":false,"grade_id":"cell-8680bae94e0b8faf","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"markdown","source":"## Error around this cell","metadata":{"id":"1CF0GrU96Zp3"}},{"cell_type":"code","source":"### Ex-3-Task-1\n\nfrom xgboost import XGBClassifier\n\n\nxgb = None\n### BEGIN SOLUTION\n# your code here\nxgb = XGBClassifier(n_estimators = 100, random_state = RANDOM_STATE)\n### END SOLUTION\nxgb.fit(X_train, y_train)\nprint(\"XGBClassifer with default parameters:\\n\")\nprint(xgb)","metadata":{"deletable":false,"id":"JTDajYP9wsI6","nbgrader":{"cell_type":"code","checksum":"902cf406b95a5f31c72d3aa5d81bb1d6","grade":false,"grade_id":"cell-9070fe216cafb265","locked":false,"schema_version":3,"solution":true,"task":false},"tags":["Ex-3-Task-1"],"execution":{"iopub.status.busy":"2022-06-25T11:37:29.265054Z","iopub.execute_input":"2022-06-25T11:37:29.265930Z","iopub.status.idle":"2022-06-25T11:37:37.252906Z","shell.execute_reply.started":"2022-06-25T11:37:29.265883Z","shell.execute_reply":"2022-06-25T11:37:37.252089Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"assert xgb is not None","metadata":{"deletable":false,"id":"co-fgNlBwsI_","nbgrader":{"cell_type":"code","checksum":"24cfb6fad2b1d72567e2b893e89f7604","grade":true,"grade_id":"cell-f3b03e893eedfef4","locked":true,"points":1,"schema_version":3,"solution":false,"task":false},"tags":["Ex-3-Task-1"],"execution":{"iopub.status.busy":"2022-06-25T11:37:37.254098Z","iopub.execute_input":"2022-06-25T11:37:37.254564Z","iopub.status.idle":"2022-06-25T11:37:37.258624Z","shell.execute_reply.started":"2022-06-25T11:37:37.254529Z","shell.execute_reply":"2022-06-25T11:37:37.257744Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"### Model Evaluation\n","metadata":{"deletable":false,"id":"2MfIlj_wwsJE","nbgrader":{"cell_type":"markdown","checksum":"f130a7d40b1ee9a3660c48a0b5c72473","grade":false,"grade_id":"cell-a90137b98eb00dd1","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"code","source":"print(\"Train f1_score:\", f1_score(y_train, xgb.predict(X_train), average = 'weighted'))\nprint(\"Test f1_score:\", f1_score(y_test, xgb.predict(X_test), average = 'weighted'))","metadata":{"deletable":false,"id":"aAU-U1zAwsJF","nbgrader":{"cell_type":"code","checksum":"35f7609b23eb449cbf651b8b40b0b2ff","grade":false,"grade_id":"cell-81881a49a238d8ef","locked":true,"schema_version":3,"solution":false,"task":false},"execution":{"iopub.status.busy":"2022-06-25T11:37:37.259830Z","iopub.execute_input":"2022-06-25T11:37:37.260298Z","iopub.status.idle":"2022-06-25T11:37:37.473051Z","shell.execute_reply.started":"2022-06-25T11:37:37.260269Z","shell.execute_reply":"2022-06-25T11:37:37.471840Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"### Tree Visualization\n\n### Exercise 4: Plot the tree structure\n<b><div style=\"text-align: right\">[UNGRADED]</div></b>\n\n---\nPlot the tree structure in the cell below. You can use `plot_tree()` or `to_graphviz()` method provided by xgboost to plot the tree.\n\n**Task:** \n-  Your task is to plot the 20th tree and answer the quiz below.\n\n","metadata":{"deletable":false,"id":"Cp8cVcgkwsJL","nbgrader":{"cell_type":"markdown","checksum":"1bca7aadf0756b0974bda3c44e1d2abb","grade":false,"grade_id":"cell-80e77d38218e7c7d","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"code","source":"### Ex-4-Task-1\nfrom xgboost import plot_tree, to_graphviz\n\n\n# Plot the tree\n\n### BEGIN SOLUTION\n# your code here\nimage = to_graphviz(xgb)\n\n#Set a different dpi (work only if format == 'png')\nimage.graph_attr = {'dpi':'600'}\n\nimage.render('xgbtree')\n\nxgb.get_booster().dump_model(\"out.txt\")\n### END SOLUTION","metadata":{"deletable":false,"id":"48H5N7r-wsJM","nbgrader":{"cell_type":"code","checksum":"87f62c5d8568dc1eb993a59be3a1d757","grade":false,"grade_id":"cell-7404e01a7c17571f","locked":false,"schema_version":3,"solution":true,"task":false},"tags":["Ex-4-Task-1"],"execution":{"iopub.status.busy":"2022-06-25T11:50:11.340424Z","iopub.execute_input":"2022-06-25T11:50:11.340850Z","iopub.status.idle":"2022-06-25T11:50:11.452386Z","shell.execute_reply.started":"2022-06-25T11:50:11.340811Z","shell.execute_reply":"2022-06-25T11:50:11.451143Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"#### Q1: Based on the tree plotted above, which of the following feature is a root node in the 20th tree?\n<b><div style=\"text-align: right\">[UNGRADED]</div></b>\n\n---\nSelect the best option.\n\n1. deposit_type\n\n2. adr\n\n3. net_booking_cancelled\n\n4. required_car_parking_spaces\n\n5. total_of_special_requests\n\n\n__Task:__\nYou just need to put the correct option number on the variable `correct_option1`.\nIf your answer is deposit_type, assign `correct_option1 = 1` and so on.","metadata":{"deletable":false,"id":"k8q56l8mwsJT","nbgrader":{"cell_type":"markdown","checksum":"832d3b9c5bbfbfd6a63119c5c207db1d","grade":false,"grade_id":"cell-265ab053a0a86503","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"code","source":"### Ex-4-Task-2\ncorrect_option1 = None\n### BEGIN SOLUTION\ncorrect_option1 = 2\n# your code here\n### END SOLUTION","metadata":{"deletable":false,"id":"iRdTM9nUwsJV","nbgrader":{"cell_type":"code","checksum":"24d0e8dca640d1aa21fe9427808402b2","grade":false,"grade_id":"cell-ccab3ae4d6d9cbfa","locked":false,"schema_version":3,"solution":true,"task":false},"tags":["Ex-4-Task-2"],"execution":{"iopub.status.busy":"2022-06-25T11:51:06.513534Z","iopub.execute_input":"2022-06-25T11:51:06.513982Z","iopub.status.idle":"2022-06-25T11:51:06.520536Z","shell.execute_reply.started":"2022-06-25T11:51:06.513935Z","shell.execute_reply":"2022-06-25T11:51:06.519112Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"assert correct_option1 is not None","metadata":{"deletable":false,"id":"_e2b1h8JwsJb","nbgrader":{"cell_type":"code","checksum":"32a245d53298069b2e4b8bffd043a4a7","grade":true,"grade_id":"cell-45cc414e80d2f81c","locked":true,"points":0,"schema_version":3,"solution":false,"task":false},"tags":["Ex-4-Task-2"],"execution":{"iopub.status.busy":"2022-06-25T11:51:07.791220Z","iopub.execute_input":"2022-06-25T11:51:07.792544Z","iopub.status.idle":"2022-06-25T11:51:07.797144Z","shell.execute_reply.started":"2022-06-25T11:51:07.792490Z","shell.execute_reply":"2022-06-25T11:51:07.796016Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"### Feature importance\n\n### Exercise 5: Plot the feature importance\n<b><div style=\"text-align: right\">[UNGRADED]</div></b>\n\n---\nXGBoost provides the `feature_importance()` method to plot the importance of each feature. Based on the feature_importance plot, you need to answer the quiz below.\n\n**Task:** \n-  Plot the feature importance of the model `xgb`.\n\n","metadata":{"deletable":false,"id":"C0bjxiIhwsJg","nbgrader":{"cell_type":"markdown","checksum":"5df529774d86c13599b182617a2eeb16","grade":false,"grade_id":"cell-242babac02f7b8d7","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"code","source":"### Ex-5-Task-1\nfrom xgboost import plot_importance\n# fig, ax = plt.subplots(figsize=(10,6), dpi=300)\nNone # plot_importance(.....)\n### BEGIN SOLUTION\n# your code here\nplot_importance(xgb)\n### END SOLUTION\nplt.show()","metadata":{"deletable":false,"id":"Ed50WkR6wsJi","nbgrader":{"cell_type":"code","checksum":"2c8584cbcaec783ba6ad5082f175fc94","grade":false,"grade_id":"cell-592367a614fc5be2","locked":false,"schema_version":3,"solution":true,"task":false},"tags":["Ex-5-Task-1"],"execution":{"iopub.status.busy":"2022-06-25T11:54:48.438036Z","iopub.execute_input":"2022-06-25T11:54:48.438421Z","iopub.status.idle":"2022-06-25T11:54:48.857942Z","shell.execute_reply.started":"2022-06-25T11:54:48.438388Z","shell.execute_reply":"2022-06-25T11:54:48.856841Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"#### Q2: Based on the gain, which of the following is the most important feature?\n<b><div style=\"text-align: right\">[UNGRADED]</div></b>\n\n\n---\nSelect the best option.\n\n1. lead_time\n\n2. country\n\n3. adr\n\n4. net_booking_cancelled\n\n5. required_car_parking_spaces\n\n6. deposit_type\n\n\n__Task:__\nYou just need to put the correct option number on the variable `correct_option2`.\nIf your answer is lead_time, assign `correct_option2 = 1` and so on.","metadata":{"deletable":false,"id":"bf1yeatOwsJm","nbgrader":{"cell_type":"markdown","checksum":"59afbefad3b748f381b3611ec4f55ba7","grade":false,"grade_id":"cell-6c179d84151f969f","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"code","source":"### Ex-5-Task-2\ncorrect_option2 = None\n### BEGIN SOLUTION\ncorrect_option2 = 1\n# your code here\n### END SOLUTION","metadata":{"deletable":false,"id":"9FsVeR4uwsJr","nbgrader":{"cell_type":"code","checksum":"7c4e6f77355ce847f75ac302b8b9249e","grade":false,"grade_id":"cell-23b208ba0033d71a","locked":false,"schema_version":3,"solution":true,"task":false},"tags":["Ex-5-Task-2"],"execution":{"iopub.status.busy":"2022-06-25T11:57:33.445709Z","iopub.execute_input":"2022-06-25T11:57:33.446070Z","iopub.status.idle":"2022-06-25T11:57:33.451558Z","shell.execute_reply.started":"2022-06-25T11:57:33.446041Z","shell.execute_reply":"2022-06-25T11:57:33.450238Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"assert correct_option2 is not None","metadata":{"deletable":false,"id":"MZ9XNIl7wsJ0","nbgrader":{"cell_type":"code","checksum":"b2c98a78b400002d8ec98c38a8dd20d7","grade":true,"grade_id":"cell-8548c5efe934897a","locked":true,"points":0,"schema_version":3,"solution":false,"task":false},"tags":["Ex-5-Task-2"],"execution":{"iopub.status.busy":"2022-06-25T11:57:34.944421Z","iopub.execute_input":"2022-06-25T11:57:34.944856Z","iopub.status.idle":"2022-06-25T11:57:34.949977Z","shell.execute_reply.started":"2022-06-25T11:57:34.944822Z","shell.execute_reply":"2022-06-25T11:57:34.948831Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"### Parallelization\n\n### Exercise 6: Multithreading\n<b><div style=\"text-align: right\">[UNGRADED]</div></b>\n\n---\nAs already discussed in the theoretical part, XGBoost is known for parallelization and distributed computing. Here we are going to instantiate XGBoost with its support for multithreading. You can refer to the documentation of XGBoost on how to set the number of threads to the number of cores.\n\n**Task:**  \n- Instantiate a XGBClassifier() to variable `model` with __random_state__ set to RANDOM_STATE and set the number of threads to number of cores.\n\n","metadata":{"id":"r4jBHfvEwsJ5"}},{"cell_type":"code","source":"### Ex-6-Task-1\nmodel = None\n### BEGIN SOLUTION\n# your code here\nmodel = XGBClassifier(random_state = RANDOM_STATE, nthread = 2)\n### END SOLUTION","metadata":{"deletable":false,"id":"4fxzfOVawsJ6","nbgrader":{"cell_type":"code","checksum":"be1aa3ceb7a5ed2c4ceebcb02236ccdb","grade":false,"grade_id":"cell-90c19bb67bce3a9c","locked":false,"schema_version":3,"solution":true,"task":false},"tags":["Ex-6-Task-1"],"execution":{"iopub.status.busy":"2022-06-25T11:57:41.020906Z","iopub.execute_input":"2022-06-25T11:57:41.021358Z","iopub.status.idle":"2022-06-25T11:57:41.028278Z","shell.execute_reply.started":"2022-06-25T11:57:41.021321Z","shell.execute_reply":"2022-06-25T11:57:41.026933Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"### INTENTIONALLY LEFT BLANK","metadata":{"deletable":false,"id":"9ApKHxgqwsKA","nbgrader":{"cell_type":"code","checksum":"2c6b6de750e323cc93d784fc072af9b0","grade":true,"grade_id":"cell-77990162525d4207","locked":true,"points":0,"schema_version":3,"solution":false,"task":false},"tags":["Ex-6-Task-1"],"execution":{"iopub.status.busy":"2022-06-25T11:37:38.858252Z","iopub.status.idle":"2022-06-25T11:37:38.859049Z","shell.execute_reply.started":"2022-06-25T11:37:38.858848Z","shell.execute_reply":"2022-06-25T11:37:38.858868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Performance Monitoring and learning curve\n\nFor performance monitoring, we define a function `learning_curve()` which plots the log loss for each boosting iteration for training and validation dataset. \n\nNote: Here, test data is used for validation, but it is good practice to have a separate validation set.","metadata":{"deletable":false,"id":"UPh-UJB7wsKF","nbgrader":{"cell_type":"markdown","checksum":"b046f7aef926457d8ffa76090722654b","grade":false,"grade_id":"cell-fa5f60ec3d43e6d5","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"code","source":"def learning_curve(model, X_train, y_train, X_test, y_test):\n    \"\"\"\n    A function to plot the learning curve.\n    \n    Paramters:\n    ---------\n    model: object\n           An object instantiated with XGBoost classifier\n    X_train: array like\n             Training features\n    y_train: array like\n             Training labels\n    X_test: array like\n            Validation features\n    y_test: array like\n            Validation labels\n            \n    Returns:\n    --------\n    None\n    \n            \n    \"\"\"\n    eval_set = [(X_train, y_train),(X_test, y_test)]\n    model.fit(X_train, y_train, eval_metric = [\"logloss\"], eval_set = eval_set, verbose = False)\n    print(\"F1 Score Train: \",f1_score(y_train, model.predict(X_train), average = 'weighted'))\n    print(\"F1 Score Test: \",f1_score(y_test, model.predict(X_test), average = 'weighted'))\n    results = model.evals_result()\n    num_tree = len(results['validation_0']['logloss'])\n    plt.figure(figsize = (8,8))\n    plt.plot(range(0, num_tree), results['validation_0']['logloss'], label = 'Training')\n    plt.plot(range(0, num_tree), results['validation_1']['logloss'], label = 'Validation')\n    plt.legend()\n    plt.xlabel(\"Number of trees\")\n    plt.ylabel(\"Log loss\")\n    plt.title(\"Learning Curve\")\n    plt.show()\n\n","metadata":{"deletable":false,"id":"pKJo8Fk3wsKF","nbgrader":{"cell_type":"code","checksum":"89e6bea7b6223b4157e5b0f7f7c120f2","grade":false,"grade_id":"cell-8108ed82c8f44441","locked":true,"schema_version":3,"solution":false,"task":false},"execution":{"iopub.status.busy":"2022-06-25T11:57:46.183213Z","iopub.execute_input":"2022-06-25T11:57:46.183628Z","iopub.status.idle":"2022-06-25T11:57:46.192893Z","shell.execute_reply.started":"2022-06-25T11:57:46.183594Z","shell.execute_reply":"2022-06-25T11:57:46.192009Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"### Exercise 7: Learning Curve\n<b><div style=\"text-align: right\">[UNGRADED]</div></b>\n\n---\nA function `learning_curve()` is defined above. Use this function to plot the learning curve for the training and validation dataset. Here we will be using the test set for validation.\n**Task:**  \n- Instantiate a XGBClassifier() to variable `model` with __n_estimators__ set to 100 , __max_depth__ set to 4, and __random_state__ set to RANDOM_STATE.\n-  Use the function `learning_curve()` to plot the learning curve of the model `xgb`. We have already instantiated `xgb` a few cells back.\n","metadata":{"deletable":false,"id":"C56MY88twsKI","nbgrader":{"cell_type":"markdown","checksum":"870caf6b331df5b6c8054b42a7d75b53","grade":false,"grade_id":"cell-f63ef012dc1b7da3","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"code","source":"### Ex-7-Task-1\nmodel = None\n# Plot learning curve\n### BEGIN SOLUTION\nmodel = XGBClassifier(n_estimators = 100, max_depth=4, random_state = RANDOM_STATE)\n# your code here\nlearning_curve(model, X_train, y_train, X_test, y_test)\n### END SOLUTION","metadata":{"deletable":false,"id":"7aq5FtPYwsKJ","nbgrader":{"cell_type":"code","checksum":"234c91da0fca039b4c5e692d4d9577f7","grade":false,"grade_id":"cell-d3604250f303b2de","locked":false,"schema_version":3,"solution":true,"task":false},"tags":["Ex-7-Task-1"],"execution":{"iopub.status.busy":"2022-06-25T11:59:09.845480Z","iopub.execute_input":"2022-06-25T11:59:09.845830Z","iopub.status.idle":"2022-06-25T11:59:16.359676Z","shell.execute_reply.started":"2022-06-25T11:59:09.845802Z","shell.execute_reply":"2022-06-25T11:59:16.358304Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"#### Q3: Recalling evaluation results of random forest trained few cells above and analyzing the above learning curve shows that our xgboost model is  ____?\n<b><div style=\"text-align: right\">[UNGRADED]</div></b>\n\n---\nSelect the best option.\n\n1. optimally fitted\n\n2. overfitted\n\n3. underfitted\n\n\n__Task:__\nYou just need to put the correct option number on the variable `correct_option3`.\nIf your answer is overfitted, assign `correct_option3 = 2` and so on.","metadata":{"deletable":false,"id":"inOMafAZwsKM","nbgrader":{"cell_type":"markdown","checksum":"1b64a50e4233c7746fd5a1f889b80390","grade":false,"grade_id":"cell-752ba7a103e50450","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"code","source":"### Ex-7-Task-2\ncorrect_option3 = None\n### BEGIN SOLUTION\n# your code here\ncorrect_option3 = 2\n### END SOLUTION","metadata":{"deletable":false,"id":"9xDBfdZSAxQ-","nbgrader":{"cell_type":"code","checksum":"513cfe81ccc49e5ee4b835e636e05488","grade":false,"grade_id":"cell-9168700a9e95e753","locked":false,"schema_version":3,"solution":true,"task":false},"tags":["Ex-7-Task-2"],"execution":{"iopub.status.busy":"2022-06-25T11:59:56.459913Z","iopub.execute_input":"2022-06-25T11:59:56.460306Z","iopub.status.idle":"2022-06-25T11:59:56.464915Z","shell.execute_reply.started":"2022-06-25T11:59:56.460273Z","shell.execute_reply":"2022-06-25T11:59:56.463780Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"assert correct_option3 is not None","metadata":{"deletable":false,"id":"EqvwXBIpwsKN","nbgrader":{"cell_type":"code","checksum":"a7db82b57f3d89156a93633bca3c1e51","grade":true,"grade_id":"cell-680e212f211f9eae","locked":true,"points":0,"schema_version":3,"solution":false,"task":false},"tags":["Ex-7-Task-2"],"execution":{"iopub.status.busy":"2022-06-25T11:59:57.707264Z","iopub.execute_input":"2022-06-25T11:59:57.707671Z","iopub.status.idle":"2022-06-25T11:59:57.712881Z","shell.execute_reply.started":"2022-06-25T11:59:57.707633Z","shell.execute_reply":"2022-06-25T11:59:57.711944Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"### Exercise 8: Improving performance\n<b><div style=\"text-align: right\">[POINTS: 1]</div></b>\n\n---\nBased on your answer, if the model is overfitted, under fitted, or optimally fitted, you need to perform a few experiments and improve its performance. The test f1-score of the model should be above 89.00%\n\nHint: If the model is overfitted, you can perform shrinkage, reduce the depth of the tree, apply regularization, etc. Similarly, if the model is under fitted, you can increase the number of iterations and the tree depth.\n\n**Task:**  \n- Instantiate a XGBClassifier() to variable `model` with the parameters you think are suitable for improving performance.\n- Note: The test f1 score of your model should be equal or above 0.8900 to get the marks.\n","metadata":{"deletable":false,"id":"bfLb4QKawsKX","nbgrader":{"cell_type":"markdown","checksum":"1795de9ba30206736841cbfa9aec9f2a","grade":false,"grade_id":"cell-ae5d7743776fa417","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"code","source":"### Ex-8-Task-1\nmodel = None\n### BEGIN SOLUTION\n# your code here\nmodel = XGBClassifier(n_estimators = 200, max_depth=20, random_state = RANDOM_STATE)\n### END SOLUTION\nmodel.fit(X_train, y_train)\npickle.dump(model, open(\"model.pickle.dat\", \"wb\"))\n\nprint(\"Train f1_score:\", f1_score(y_train, model.predict(X_train), average = 'weighted'))\nprint(\"Test f1_score:\", f1_score(y_test, model.predict(X_test), average = 'weighted'))","metadata":{"deletable":false,"id":"-hgayJeYwsKY","nbgrader":{"cell_type":"code","checksum":"e5f371d76cd7dac23d08b4bfae553092","grade":false,"grade_id":"cell-c6c3726bbeeded05","locked":false,"schema_version":3,"solution":true,"task":false},"tags":["Ex-8-Task-1"],"execution":{"iopub.status.busy":"2022-06-25T12:03:05.362278Z","iopub.execute_input":"2022-06-25T12:03:05.362743Z","iopub.status.idle":"2022-06-25T12:04:04.507382Z","shell.execute_reply.started":"2022-06-25T12:03:05.362707Z","shell.execute_reply":"2022-06-25T12:04:04.506279Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"### INTENTIONALLY LEFT BLANK","metadata":{"deletable":false,"id":"KK6gIaq9wsKc","nbgrader":{"cell_type":"code","checksum":"c7a2165d724025bb5284e1b6e9e9d2c0","grade":true,"grade_id":"cell-18ef62f4ca805457","locked":true,"points":1,"schema_version":3,"solution":false,"task":false},"tags":["Ex-8-Task-1"],"execution":{"iopub.status.busy":"2022-06-25T11:37:38.869795Z","iopub.status.idle":"2022-06-25T11:37:38.870222Z","shell.execute_reply.started":"2022-06-25T11:37:38.870048Z","shell.execute_reply":"2022-06-25T11:37:38.870065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Tuning\n\nA function `tuning_curve()` is defined, which tunes the xgboost . Here `param_name` is the name of the parameter, and `param_range` is the corresponding range of the parameter's value. This function plot the log loss for different value of these parameters. The plot has a vertical line with a central dot corresponding to each value of the parameter.  The vertical length represents the standard deviation of log loss for three cross-fold validation. Similarly, the central dot represents the mean log loss for three cross-fold validation.","metadata":{"deletable":false,"id":"2EPPp2jWwsKg","nbgrader":{"cell_type":"markdown","checksum":"71f6dc878e6e62d4e3c933b5bfa94449","grade":false,"grade_id":"cell-6ab792baf95be725","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"code","source":"from sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import StratifiedKFold\n\n\ndef tuning_curve(param_name, param_range):\n    \"\"\"\n    A function to perform hyperparameter tuning.\n    \n    A 3 fold stratified cross validation is performed for each value of parameter.\n    \n    \n    Parameters:\n    ----------\n    param_name: str\n                Name of the parameter on which to perform hyperparamter tuning.\n    param_range: list\n                 Range of parameter to perform grid search\n                 \n    Returns:\n    -------\n    None\n    \"\"\"\n    mean = []\n    std = []\n    for n in param_range:\n        arg = dict()\n        arg[param_name] = n\n        model = XGBClassifier(random_state = RANDOM_STATE,n_jobs = -1,  **arg)\n        skfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)\n        scores = cross_validate(model, X_train, y_train, scoring = ['neg_log_loss'], cv = skfold)\n        mean_temp = np.abs(scores['test_neg_log_loss']).mean()\n        mean.append(mean_temp)\n        std_temp = np.abs(scores['test_neg_log_loss']).std()/2.0\n        std.append(std_temp)\n    plt.errorbar(param_range, mean, std, fmt = 'o') \n    plt.xlabel(\"{}\".format(param_name))\n    plt.ylabel(\"{}\".format(\"Log loss\"))\n    plt.title(\"Cross Validation Score\")\n    plt.show()\n\n","metadata":{"deletable":false,"id":"eg_vu2BBwsKg","nbgrader":{"cell_type":"code","checksum":"4d4b5859b25869099aee7f7411054874","grade":false,"grade_id":"cell-fcd0aa29a62fdc7c","locked":true,"schema_version":3,"solution":false,"task":false},"execution":{"iopub.status.busy":"2022-06-25T12:04:15.275142Z","iopub.execute_input":"2022-06-25T12:04:15.275519Z","iopub.status.idle":"2022-06-25T12:04:15.285619Z","shell.execute_reply.started":"2022-06-25T12:04:15.275487Z","shell.execute_reply":"2022-06-25T12:04:15.284504Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"### Exercise 9: Tuning L1-Regularization term.\n<b><div style=\"text-align: right\">[UNGRADED]</div></b>\n\n---\nA function `tuning_curve()` is defined above. Use this function to tune L1 regularization term in the range $[0, 0.4, 1, 5, 10]$\n\n**Task:**  \n- Use function `tuning_curve()` to tune the parameter `reg_alpha` in the range $[0, 0.4, 1, 5, 10]$ and answer the following quiz.\n","metadata":{"deletable":false,"id":"M46PQhAKwsKj","nbgrader":{"cell_type":"markdown","checksum":"ed766f124344524470343438331e7072","grade":false,"grade_id":"cell-7abdb069e9449f28","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"code","source":"### Ex-9-Task-1\n\nNone # Call function tuning_curve() to tune reg_alpha in the given range\n\n### BEGIN SOLUTION\n# your code here\ntuning_curve(\"reg_alpha\", [0,0.4,1,5,10])\n### END SOLUTION","metadata":{"deletable":false,"id":"o_ES-JPNwsKl","nbgrader":{"cell_type":"code","checksum":"52d80fd0a0f208e0f067c0fe5aca4886","grade":false,"grade_id":"cell-e76c5f3f70d295d3","locked":false,"schema_version":3,"solution":true,"task":false},"tags":["Ex-9-Task-1"],"execution":{"iopub.status.busy":"2022-06-25T12:05:08.552960Z","iopub.execute_input":"2022-06-25T12:05:08.553351Z","iopub.status.idle":"2022-06-25T12:06:19.393308Z","shell.execute_reply.started":"2022-06-25T12:05:08.553318Z","shell.execute_reply":"2022-06-25T12:06:19.392347Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"#### Q4: From the above curve, which of the following value of reg_alpha yields the best performance?\n<b><div style=\"text-align: right\">[UNGRADED]</div></b>\n\n---\n\nSelect the best option.\n\n1. 0\n\n2. 0.4\n\n3. 1\n\n4. 5\n\n5. 10\n\n\n__Task:__\nYou just need to put the correct option number on the variable `correct_option4`.\nIf your answer is 1, assign `correct_option4 = 3` and so on.\n\n","metadata":{"deletable":false,"id":"eciMTlsjwsKo","nbgrader":{"cell_type":"markdown","checksum":"f6db85897e9f7633b0afa7255a9f3cde","grade":false,"grade_id":"cell-e947185a223b2ed4","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"code","source":"### Ex-9-Task-2\ncorrect_option4 = None\n### BEGIN SOLUTION\n# your code here\ncorrect_option4 = 3\n### END SOLUTION","metadata":{"deletable":false,"id":"05rB4PBzwsKo","nbgrader":{"cell_type":"code","checksum":"1df35f2e0ccd3afbb48c11f0258e35bf","grade":false,"grade_id":"cell-e6f79de5d9099766","locked":false,"schema_version":3,"solution":true,"task":false},"tags":["Ex-9-Task-2"],"execution":{"iopub.status.busy":"2022-06-25T12:06:54.249593Z","iopub.execute_input":"2022-06-25T12:06:54.249943Z","iopub.status.idle":"2022-06-25T12:06:54.254451Z","shell.execute_reply.started":"2022-06-25T12:06:54.249917Z","shell.execute_reply":"2022-06-25T12:06:54.253602Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"assert correct_option4 is not None","metadata":{"deletable":false,"id":"YvRtF_WRwsKr","nbgrader":{"cell_type":"code","checksum":"5f2b6f1b9d602ee2cbb3429b39ecd557","grade":true,"grade_id":"cell-2f34af50e3ed0e9d","locked":true,"points":0,"schema_version":3,"solution":false,"task":false},"tags":["Ex-9-Task-2"],"execution":{"iopub.status.busy":"2022-06-25T12:06:58.152596Z","iopub.execute_input":"2022-06-25T12:06:58.152952Z","iopub.status.idle":"2022-06-25T12:06:58.158698Z","shell.execute_reply.started":"2022-06-25T12:06:58.152924Z","shell.execute_reply":"2022-06-25T12:06:58.157175Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"__Congratulation!!!!!!!!!!!!!__\n\n__You have completed level 1__","metadata":{"deletable":false,"id":"Yie7qnu3wsKv","nbgrader":{"cell_type":"markdown","checksum":"e04704b3820c9528f1471a4ec735ca75","grade":false,"grade_id":"cell-37b52dd2aa626f09","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"markdown","source":"## Level 2+3\n\n## Learning Objective (Level2+Level 3)\n<b><div style=\"text-align: right\">[POINTS: 6]</div></b>\n\n- Implement Gradient Boosting Regressor from scratch.\n\n- Compare the performance of gradient boosting regressor implement from scratch with Sklearn's gradient boosting regressor.\n\n","metadata":{"deletable":false,"id":"IX6VJobpwsKw","nbgrader":{"cell_type":"markdown","checksum":"21148ea71a2c3fffcd750d9a0850a18e","grade":false,"grade_id":"cell-b667e8e8b3636142","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"markdown","source":"### Dataset Description\n\nWe will use a synthetic dataset for this part. A synthetic dataset is generated using Sklearn's `make_regression()` method.\n\n---\nNumber of Instances: 100\n\nNumber of Attributes:4\n\n---\nThe features are labeled `x1`, `x2`,`x3`,`x4`, and the output value is labeled `target`.\n","metadata":{"deletable":false,"id":"V5t25PcIwsKx","nbgrader":{"cell_type":"markdown","checksum":"b539f0638b77ac797b9f2443444155c4","grade":false,"grade_id":"cell-db838318b41e3f7d","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"code","source":"from sklearn.datasets import make_regression\n\n\nRANDOM_STATE = 7\nX, y = make_regression(n_samples=100, n_features=4, n_informative=3, bias = 2,noise=0.05, random_state = RANDOM_STATE)\ndf = pd.DataFrame(X, columns = ['x1', 'x2', 'x3', 'x4'])\ndf['target']= y\ndf.head()","metadata":{"deletable":false,"id":"MDvsa8egwsKx","nbgrader":{"cell_type":"code","checksum":"5aefc0504f5a9945cdec95c008966c62","grade":false,"grade_id":"cell-d43477defd50fd3b","locked":true,"schema_version":3,"solution":false,"task":false},"execution":{"iopub.status.busy":"2022-06-25T12:07:30.858131Z","iopub.execute_input":"2022-06-25T12:07:30.858534Z","iopub.status.idle":"2022-06-25T12:07:30.951484Z","shell.execute_reply.started":"2022-06-25T12:07:30.858489Z","shell.execute_reply":"2022-06-25T12:07:30.950319Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"### Scatter plot","metadata":{"deletable":false,"id":"L9fe-DOjwsK1","nbgrader":{"cell_type":"markdown","checksum":"399d77eb89f479cc6592ab8166537fb2","grade":false,"grade_id":"cell-bd14aeadf62f03f4","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"markdown","source":"If you would like, you could visualize the scatter plot of individual features with respect to the target variable. Moreover, if you like to understand better the distribution of the data, you can experiment yourself.","metadata":{"deletable":false,"id":"gCJllXViwsK1","nbgrader":{"cell_type":"markdown","checksum":"8ba972628ecccef62c8ad3c30e951745","grade":false,"grade_id":"cell-0589adfec84c9f9a","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"code","source":"# Perform experiment to understand data distribution if needed.\nplt.scatter(X[:,0], y)\nplt.ylabel(\"Output/independent variable\")\nplt.xlabel(\"Input/dependet variable\")\nplt.show()","metadata":{"deletable":false,"id":"EPrD4CUZwsK3","nbgrader":{"cell_type":"code","checksum":"eb3e326074439174f2d87861e2c753c3","grade":false,"grade_id":"cell-397b9432fd9d4d86","locked":true,"schema_version":3,"solution":false,"task":false},"execution":{"iopub.status.busy":"2022-06-25T12:07:37.357744Z","iopub.execute_input":"2022-06-25T12:07:37.358124Z","iopub.status.idle":"2022-06-25T12:07:37.551207Z","shell.execute_reply.started":"2022-06-25T12:07:37.358086Z","shell.execute_reply":"2022-06-25T12:07:37.550014Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"markdown","source":"### Train Test Split\nAs usual, we will keep 80% of the data for training and the rest for testing.","metadata":{"deletable":false,"id":"HQxBrCMAwsK7","nbgrader":{"cell_type":"markdown","checksum":"cabfee13e8f5fb63e9b1d3af87a202d6","grade":false,"grade_id":"cell-f3f5e12329749570","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = RANDOM_STATE)","metadata":{"deletable":false,"id":"sHr2YzgbwsK8","nbgrader":{"cell_type":"code","checksum":"21828956dbeee82cc99280c096467dd5","grade":false,"grade_id":"cell-8dda2947d86adb91","locked":true,"schema_version":3,"solution":false,"task":false},"execution":{"iopub.status.busy":"2022-06-25T12:07:40.656386Z","iopub.execute_input":"2022-06-25T12:07:40.656794Z","iopub.status.idle":"2022-06-25T12:07:40.663286Z","shell.execute_reply.started":"2022-06-25T12:07:40.656761Z","shell.execute_reply":"2022-06-25T12:07:40.662296Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"## Gradient Boosting Regressor from scratch\nIn this section, we will implement a gradient boosting regressor from scratch. Each base learner will be a decision tree. For this, we will use Sklearn's `DecisionTreeRegressor()` object.\n\nHere is a pseudo-code for gradient boosting regressor.\n```\nAlgorithm:\n```\n> 1. initialize $F_0= \\frac{1}{N}\\sum_{i=1}^N y_i$\n2. for $t=1$ to $M$ do\n3. > calculate negative gradients $-g(\\mathbf{x_i})$; where $-g(\\mathbf{x_i})= -\\frac{\\partial L(y_i, F(\\mathbf{x_i}))}{\\partial F(\\mathbf{x_i})}\\bigg{|}_{F = F_{t-1}}$\n4. > fit a base-learner model $h$ to negative gradients $-g(\\mathbf{x_i})$\n5. > update the function: $F_t=F_{t-1} + \\alpha h(\\mathbf{x})$; where $\\alpha$ is a shrinkage\n6. end for","metadata":{"deletable":false,"id":"OdD_9-8twsK_","nbgrader":{"cell_type":"markdown","checksum":"3dd35b77bb9cf09bb1fe20e213809b06","grade":false,"grade_id":"cell-2e777240a07996e8","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"markdown","source":"Below is a skeleton class for the gradient boosting regressor. We have already defined a constructor for initializing different attributes like `learning_rate`, `max_depth` of each tree, and `n_estimators` for the number of boosting iterations. The attribute `estimators` is a list of each trained base learner.\n\n### Exercise 10: Gradient Boosting Regressor from scratch\n<b><div style=\"text-align: right\">[POINTS: 1+3+1]</div></b>\n\n---\nThis exercise is divided into three different tasks. Through these three tasks, you will create a gradient boosting regressor.\n\n**Task 1: Computation of negative gradient** \n<b><div style=\"text-align: right\">[POINTS: 1]</div></b>\n\nWe have defined a static method `negative_gradient` which should return the negative gradient when actual label $y$ and predicted label $\\hat{y}$ are given. You need to complete this function.\n\n-  Your task is to assign the negative gradient the the variable `grad`. Suppose we are using the following loss function $$L(y,\\hat{y})= \\frac{1}{2}(y-\\hat{y})^2$$ \nwhere, $y$ is the actual label and $\\hat{y}$ is the predicted label.\n\n\n**Task 2: Fit the model** \n\n<b><div style=\"text-align: right\">[POINTS: 3]</div></b>\n\n\nIn this task, we are going to fit our model with the training dataset. We have defined a function `fit(X,y)` in the class `Gradient_Boosting_Regressor` where, X is the training features, and y is the training label. As already discussed in the reading material, the first prediction is the average of output label. Here we have defined two attributes, `average` and `base_prediction`. `base_prediction` is a vector of average value with a length equal to the number of instances in the training data. \n\n\n- Compute the negative_gradient using the above defined function and put it in the variable `pseduo_residual`.\n- Instantiate a decision tree regressor(from sklearn) on variable `tree` setting `max_depth` to the variable provided in the class constructor and setting `random_state` to RANDOM_STATE.\n- Fit the tree on input X and pseudo_residual as a target.\n- Update `base_prediction` with the prediction of the current tree. Note: The prediction of each tree should be downscaled by shrinkage. Please replace 0 with your own code.\n\n**Task 3: Prediction by model** \n\n<b><div style=\"text-align: right\">[POINTS: 1]</div></b>\n\n\nIn this exercise, we are going to make a prediction based on the input data. We have defined a function `predict(X)` in the class `Gradient_Boosting_Regressor` where, X is a feature for which we want to make a prediction. Here we have initialized the variable `predictions` by the average value of the training label. We want to return the final prediction made by the model.\n\n\n- The average prediction is already assigned to the variable `predictions`. Your task is to add the predictions made by each estimator to the variable `predictions`. Please replace 0 with your code.\n\n\nThe last method, `staged_predict()` is a generator that returns the prediction for each boosting iterations.","metadata":{"deletable":false,"id":"078dpGJLwsLA","nbgrader":{"cell_type":"markdown","checksum":"def6f6ac365797d3e3401f146966d377","grade":false,"grade_id":"cell-07955f911d589c73","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"code","source":"### Ex-10-Task-1\n\nfrom sklearn.tree import DecisionTreeRegressor\n\nclass Gradient_Boosting_Regressor:\n    \"\"\"\n    Gradient boosting for regression.\n    \n    This implementation uses a mean square error loss function.\n    \n    Parameters:\n    ----------\n    learning_rate: int\n                   Learning rate or shrinkage parameter (the default is 0.1)\n    max_depth: int\n               Maximum allowed depth for each tree (the default value is 4)\n    n_estimators: int\n                  The total number of boosting operations (the default value is 5)  \n                   \n    \"\"\"\n    def __init__(self, learning_rate = 0.1, max_depth = 3, n_estimators = 5):\n        self.learning_rate = learning_rate\n        self.max_depth = max_depth\n        self.n_estimators = n_estimators\n        self.estimators = []\n        \n        \n    @staticmethod\n    def negative_gradient(y, y_pred):\n        \"\"\"Compute and return the negative gradient. \"\"\"\n        grad = None\n        \n        grad = y-y_pred\n        \n        return grad\n    \n    \n    def fit(self, X, y):\n        \"\"\"Fit the model on data X and y\"\"\"\n        self.average = np.mean(y)\n        self.base_prediction = np.array([np.mean(y)]*len(y))\n        \n        for estimators in range(self.n_estimators):\n            pseudo_residuals = None\n            tree = None \n            None # tree.fit(...)\n            self.base_prediction += 0 # None ########### WHAT IS THE USE OF THIS LINE?\n            ### BEGIN SOLUTION\n            # your code here\n            tree = DecisionTreeRegressor(max_depth=1, max_leaf_nodes=3)\n            tree.fit(X, y)\n            \n            \n            ### END SOLUTION\n            self.estimators.append(tree)\n            \n            \n    def predict(self, X):\n        \"\"\"Make prediction by the model on data X.\"\"\"\n        predictions = np.array([self.average]*X.shape[0])\n        for estimator in self.estimators:\n            predictions += 0 # None\n            \n            predictions += self.learning_rate*estimator.predict(X)\n            \n        return predictions\n    \n    \n    def staged_predict(self, X):\n        \"\"\"A generator which returns the prediction at each boosting iteration.\"\"\"\n        predictions = np.array([self.average]*X.shape[0])\n        \n        for estimator in self.estimators:\n            predictions += self.learning_rate*estimator.predict(X)\n            yield predictions\n\n        ","metadata":{"deletable":false,"id":"NOP9uMawwsLA","nbgrader":{"cell_type":"code","checksum":"7e5642f650a4491a4895763b403b7b29","grade":false,"grade_id":"cell-a577ca77eb16fb05","locked":false,"schema_version":3,"solution":true,"task":false},"tags":["Ex-10-Task-1"],"execution":{"iopub.status.busy":"2022-06-25T12:54:36.825943Z","iopub.execute_input":"2022-06-25T12:54:36.826828Z","iopub.status.idle":"2022-06-25T12:54:36.839515Z","shell.execute_reply.started":"2022-06-25T12:54:36.826789Z","shell.execute_reply":"2022-06-25T12:54:36.838505Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"model = Gradient_Boosting_Regressor()\nmodel.fit(X_train, y_train)\nassert not np.array_equal(model.predict(X_train), np.array([np.mean(y_train)]*len(y_train))), \"Make sure you have implemented the code for fit and predict methods.\"\n","metadata":{"deletable":false,"id":"Y9jBuEOTwsLC","nbgrader":{"cell_type":"code","checksum":"6e0d662a4771db4f854363df6da93418","grade":true,"grade_id":"cell-b9efbc219be797d3","locked":true,"points":5,"schema_version":3,"solution":false,"task":false},"tags":["Ex-10-Task-1"],"execution":{"iopub.status.busy":"2022-06-25T12:54:39.471338Z","iopub.execute_input":"2022-06-25T12:54:39.471760Z","iopub.status.idle":"2022-06-25T12:54:39.481204Z","shell.execute_reply.started":"2022-06-25T12:54:39.471724Z","shell.execute_reply":"2022-06-25T12:54:39.479914Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation and Comparision\nIn this and coming sections, we will first evaluate the gradient boosting regressor that we just built from scratch and then compare it with the Sklearn's gradient boosting regressor.","metadata":{"deletable":false,"id":"lZQXk1LKwsLK","nbgrader":{"cell_type":"markdown","checksum":"f37fc33a70b7a7787b3a386eb36bbe32","grade":false,"grade_id":"cell-923533ed49764d9a","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"markdown","source":"Let's see how our model has performed.","metadata":{"deletable":false,"id":"6lBICO5cwsLL","nbgrader":{"cell_type":"markdown","checksum":"bf7079289461f0a4521138fd8cb9014f","grade":false,"grade_id":"cell-b6c7066b96b6b819","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"code","source":"from sklearn.metrics import r2_score\n\ncustom_gbm = Gradient_Boosting_Regressor(learning_rate = 0.2, max_depth = 3, n_estimators = 4)\ncustom_gbm.fit(X_train, y_train)\n\n\nprint(\"r2_score:\", r2_score(y_test, custom_gbm.predict(X_test)))","metadata":{"deletable":false,"id":"eEDtuZTewsLM","nbgrader":{"cell_type":"code","checksum":"870eed9ae359e68d63fc4885c9f386b4","grade":false,"grade_id":"cell-c2a36747339e6a0f","locked":true,"schema_version":3,"solution":false,"task":false},"execution":{"iopub.status.busy":"2022-06-25T12:54:44.633149Z","iopub.execute_input":"2022-06-25T12:54:44.634045Z","iopub.status.idle":"2022-06-25T12:54:44.641651Z","shell.execute_reply.started":"2022-06-25T12:54:44.634010Z","shell.execute_reply":"2022-06-25T12:54:44.640745Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":"### Visualization\nLet's see if the prediction gets improved with the added estimators. Here we will plot the actual and predicted target value.","metadata":{"deletable":false,"id":"beLuCubewsLR","nbgrader":{"cell_type":"markdown","checksum":"cb1143a69d62ad1171ba71716f7850c8","grade":false,"grade_id":"cell-4bbd2fbc84269c97","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"code","source":"fig, ax = plt.subplots(1,4, figsize = (20,4.5), sharex = True)\nfig.suptitle(\"Prediction made by our custom gradient boosting regressor\")\nfor i, pred in enumerate(custom_gbm.staged_predict(X_test)):\n    ax[i].scatter(y_test, pred, marker = 'o')\n    ax[i].set_title(\"n_estimators={}; r2_score={:04.2f}\".format(i+1, r2_score(y_test, pred)))\n    ax[i].set_xlabel(\"Actual value\")\n    ax[i].set_ylabel(\"Predicted value\")\nplt.show()","metadata":{"deletable":false,"id":"unyAB9CRwsLS","nbgrader":{"cell_type":"code","checksum":"87da27857bc3f08915ae8b5a8ac1148a","grade":false,"grade_id":"cell-0859ece951bdb673","locked":true,"schema_version":3,"solution":false,"task":false},"execution":{"iopub.status.busy":"2022-06-25T12:54:49.278337Z","iopub.execute_input":"2022-06-25T12:54:49.279379Z","iopub.status.idle":"2022-06-25T12:54:49.800145Z","shell.execute_reply.started":"2022-06-25T12:54:49.279343Z","shell.execute_reply":"2022-06-25T12:54:49.799070Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":"#### Q5: With our custom gradient boosting regressor, the prediction has ______ with boosting iteration?\n<b><div style=\"text-align: right\">[UNGRADED]</div></b>\n\n---\nSelect the best option.\n\n1. improved\n\n2. degraded\n\n3. remained same\n\n\n__Task:__\nYou just need to put the correct option number on the variable `correct_option5`.\nIf your answer is degraded, assign `correct_option5 = 1` and so on.\n","metadata":{"deletable":false,"id":"a28anUbpwsLV","nbgrader":{"cell_type":"markdown","checksum":"71986ca2206afe668c27ec2ebae9402e","grade":false,"grade_id":"cell-95ef400d33ab74e6","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"code","source":"### Ex-10-Task-2\n\ncorrect_option5 = None\n### BEGIN SOLUTION\ncorrect_option5 = 2\n### END SOLUTION","metadata":{"deletable":false,"id":"oQv2PyUWwsLV","nbgrader":{"cell_type":"code","checksum":"6e494b245f744fad8221ca63fd6468fe","grade":false,"grade_id":"cell-76698c8e472078b9","locked":false,"schema_version":3,"solution":true,"task":false},"tags":["Ex-10-Task-2"],"execution":{"iopub.status.busy":"2022-06-25T12:56:28.711292Z","iopub.execute_input":"2022-06-25T12:56:28.711690Z","iopub.status.idle":"2022-06-25T12:56:28.717022Z","shell.execute_reply.started":"2022-06-25T12:56:28.711656Z","shell.execute_reply":"2022-06-25T12:56:28.715716Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"assert correct_option5 is not None","metadata":{"deletable":false,"id":"39wF8tIVwsLa","nbgrader":{"cell_type":"code","checksum":"00948eca5c9e17c3728a92fdbe6c08a4","grade":true,"grade_id":"cell-f90c0c9bb300b864","locked":true,"points":0,"schema_version":3,"solution":false,"task":false},"tags":["Ex-10-Task-2"],"execution":{"iopub.status.busy":"2022-06-25T11:37:38.892669Z","iopub.status.idle":"2022-06-25T11:37:38.892999Z","shell.execute_reply.started":"2022-06-25T11:37:38.892840Z","shell.execute_reply":"2022-06-25T11:37:38.892855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Gradient Boosting Regressor in sklearn\nLet's see how our model compared with the gradient boosting regressor in sklearn.\n\n### Exercise 11: Training Sklearn's GradientBoostingRegressor\n\n---\n<b><div style=\"text-align: right\">[POINTS: Ungraded]</div></b>\n\nIn this exercise, we are going to train Sklearn's GradientBoostingRegressor.\n\n**Task:** \n- Create an object `gbm` of the `GradientBoostingRegressor` class setting criterion to `squared_error`, n_estimators to 4, max_depth to 3, learning_rate to 0.2 and random_state to RANDOM_STATE.\n- Fit the object on the training set `X_train`, and `y_train`.\n\n","metadata":{"deletable":false,"id":"lOwaWEnOwsLf","nbgrader":{"cell_type":"markdown","checksum":"349f8ae66851ebc02513a2233cbcd678","grade":false,"grade_id":"cell-b4c1f0242df52fde","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"code","source":"### Ex-11-Task-1\nfrom sklearn.ensemble import GradientBoostingRegressor\n\ngbm = None\n# Fit the model \n### BEGIN SOLUTION\n# your code here\ngbm = GradientBoostingRegressor(criterion = \"squared_error\", n_estimators = 4, max_depth = 3, learning_rate = 0.2, random_state = RANDOM_STATE)\ngbm.fit(X_train, y_train)\n### END SOLUTION\nprint(\"r2_score: \", r2_score(y_test, gbm.predict(X_test)))","metadata":{"deletable":false,"id":"_se8m4-qwsLf","nbgrader":{"cell_type":"code","checksum":"c78544f33db6b6b92df21756fe92c68b","grade":false,"grade_id":"cell-f5b4d71276ea35b7","locked":false,"schema_version":3,"solution":true,"task":false},"tags":["Ex-11-Task-1"],"execution":{"iopub.status.busy":"2022-06-25T12:58:37.366357Z","iopub.execute_input":"2022-06-25T12:58:37.366773Z","iopub.status.idle":"2022-06-25T12:58:37.378490Z","shell.execute_reply.started":"2022-06-25T12:58:37.366739Z","shell.execute_reply":"2022-06-25T12:58:37.377261Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"assert gbm is not None","metadata":{"deletable":false,"id":"5P9ZkU5TwsLl","nbgrader":{"cell_type":"code","checksum":"b8e4c6c4a2d5c5a97340a89ed735a0ad","grade":true,"grade_id":"cell-6e7715fbea42734b","locked":true,"points":0,"schema_version":3,"solution":false,"task":false},"tags":["Ex-11-Task-1"],"execution":{"iopub.status.busy":"2022-06-25T12:58:40.655193Z","iopub.execute_input":"2022-06-25T12:58:40.656240Z","iopub.status.idle":"2022-06-25T12:58:40.660688Z","shell.execute_reply.started":"2022-06-25T12:58:40.656199Z","shell.execute_reply":"2022-06-25T12:58:40.659648Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"markdown","source":"### Visualization\nLet's visualize how the prediction made by Sklearn's gradient boosting regressor looks.","metadata":{"deletable":false,"id":"FNI07SztwsLq","nbgrader":{"cell_type":"markdown","checksum":"f371ceaa33e64122fcdab4ac0449c32c","grade":false,"grade_id":"cell-2b0adfbae73edfa0","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"code","source":"fig, ax = plt.subplots(1,4, figsize = (20,5), sharex = True, sharey=True)\nfig.suptitle(\"Prediction made by sklearn's gradient boosting regressor\")\nfor i, pred in enumerate(gbm.staged_predict(X_test)):\n    ax[i].scatter(y_test, pred, marker = 'o')\n    ax[i].set_title(\"n_estimators={}; r2_score={:04.2f}\".format(i+1, r2_score(y_test, pred)))\n    ax[i].set_xlabel(\"Actual value\")\n    ax[i].set_ylabel(\"Predicted value\")\nplt.show()","metadata":{"deletable":false,"id":"ZN1qS2i1wsLq","nbgrader":{"cell_type":"code","checksum":"dc84290d44f230922a8fe746ed0c91e6","grade":false,"grade_id":"cell-ce8cf5516f17bcbf","locked":true,"schema_version":3,"solution":false,"task":false},"execution":{"iopub.status.busy":"2022-06-25T12:58:42.253777Z","iopub.execute_input":"2022-06-25T12:58:42.254152Z","iopub.status.idle":"2022-06-25T12:58:42.771991Z","shell.execute_reply.started":"2022-06-25T12:58:42.254122Z","shell.execute_reply":"2022-06-25T12:58:42.770802Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"markdown","source":"#### Q6: Based on the above two plots, the performance of Sklearn's gradient boosting regressor is ______ our custom gradient boosting regressor?\n<b><div style=\"text-align: right\">[UNGRADED]</div></b>\n\n---\nSelect the best option.\n\n1. better than\n\n2. worse than\n\n3. same as\n\n\n__Task:__\nYou just need to put the correct option number on the variable `correct_option6`.\nIf your answer is same as, assign `correct_option6 = 3` and so on.\n","metadata":{"deletable":false,"id":"aQNwznniwsLt","nbgrader":{"cell_type":"markdown","checksum":"ffbc5bdcdec31285d2add3308d4c07dd","grade":false,"grade_id":"cell-39c8f97d55d679e1","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"code","source":"### Ex-11-Task-2\n\ncorrect_option6 = None\n### BEGIN SOLUTION\n# your code here\ncorrect_option6 = 1\n### END SOLUTION","metadata":{"deletable":false,"id":"h6-7FqRhwsLu","nbgrader":{"cell_type":"code","checksum":"2025943f6a17f20a5c2602152e70f651","grade":false,"grade_id":"cell-ebdf39b6063cca4b","locked":false,"schema_version":3,"solution":true,"task":false},"tags":["Ex-11-Task-2"],"execution":{"iopub.status.busy":"2022-06-25T12:59:08.919798Z","iopub.execute_input":"2022-06-25T12:59:08.920360Z","iopub.status.idle":"2022-06-25T12:59:08.924373Z","shell.execute_reply.started":"2022-06-25T12:59:08.920328Z","shell.execute_reply":"2022-06-25T12:59:08.923305Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"assert correct_option6 is not None","metadata":{"deletable":false,"id":"JGF7fuyawsL4","nbgrader":{"cell_type":"code","checksum":"ea992f7208a9bbecb3ba36330db663cf","grade":true,"grade_id":"cell-2c6a58ebdfbd093d","locked":true,"points":0,"schema_version":3,"solution":false,"task":false},"tags":["Ex-11-Task-2"],"execution":{"iopub.status.busy":"2022-06-25T12:59:10.234352Z","iopub.execute_input":"2022-06-25T12:59:10.235061Z","iopub.status.idle":"2022-06-25T12:59:10.239414Z","shell.execute_reply.started":"2022-06-25T12:59:10.235015Z","shell.execute_reply":"2022-06-25T12:59:10.238677Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":"### Loss vs. boosting iterations\nWe will plot the value of mse loss at different iterations to visualize how the model's performance has improved. The function `learning_curve()` plots the mse of training and test data at each boosting iteration.","metadata":{"deletable":false,"id":"bv3aMhnXwsL7","nbgrader":{"cell_type":"markdown","checksum":"77d53610f63cb47e0471f00980b7de87","grade":false,"grade_id":"cell-0bbfda43b17a9cd1","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error as mse\n\n\ndef learning_curve(clf):\n    train_mse = []\n    test_mse = []\n    for pred in clf.staged_predict(X_train):\n        train_mse.append(mse(y_train, pred))\n    for pred in clf.staged_predict(X_test):\n        test_mse.append(mse(y_test, pred))\n    plt.plot(np.arange(clf.n_estimators)+1, train_mse, 'r', label= \"Training\")\n    plt.plot(np.arange(clf.n_estimators)+1, test_mse, 'b', label = \"Testing\")\n    plt.xlabel(\"Iterations\")\n    plt.ylabel(\"MSE loss\")\n    plt.legend()\n    plt.show()","metadata":{"deletable":false,"id":"IMxRSx_CwsL8","nbgrader":{"cell_type":"code","checksum":"e2e7f7c29ef49686b431693297320b51","grade":false,"grade_id":"cell-815d662048750719","locked":true,"schema_version":3,"solution":false,"task":false},"execution":{"iopub.status.busy":"2022-06-25T12:59:13.905641Z","iopub.execute_input":"2022-06-25T12:59:13.906205Z","iopub.status.idle":"2022-06-25T12:59:13.913045Z","shell.execute_reply.started":"2022-06-25T12:59:13.906174Z","shell.execute_reply":"2022-06-25T12:59:13.912205Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"custom_clf = Gradient_Boosting_Regressor(n_estimators = 100, max_depth = 1, learning_rate = 0.1)\ncustom_clf.fit(X_train, y_train)\nlearning_curve(custom_clf)\nprint(\"MSE:\" ,mse(y_test, custom_clf.predict(X_test)))\nprint(\"r2_score\" ,r2_score(y_test, custom_clf.predict(X_test)))","metadata":{"deletable":false,"id":"bKa9EcY0wsL-","nbgrader":{"cell_type":"code","checksum":"88cb1d93ccf5f37eb5c4eb9b17702897","grade":false,"grade_id":"cell-b80c279d4f96b3cd","locked":true,"schema_version":3,"solution":false,"task":false},"execution":{"iopub.status.busy":"2022-06-25T12:59:21.150686Z","iopub.execute_input":"2022-06-25T12:59:21.151463Z","iopub.status.idle":"2022-06-25T12:59:21.427090Z","shell.execute_reply.started":"2022-06-25T12:59:21.151399Z","shell.execute_reply":"2022-06-25T12:59:21.425921Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"clf = GradientBoostingRegressor(n_estimators = 100, max_depth = 1, learning_rate = 0.1, criterion = 'squared_error')\nclf.fit(X_train, y_train)\nlearning_curve(clf)\nprint(\"MSE:\", mse(y_test, clf.predict(X_test)))\nprint(\"r2_score\", r2_score(y_test, clf.predict(X_test)))","metadata":{"deletable":false,"id":"Yx8n8ElVwsMC","nbgrader":{"cell_type":"code","checksum":"da38df50a80d5b8b9b162f4d340ea6dc","grade":false,"grade_id":"cell-0859ee6d5bae40dd","locked":true,"schema_version":3,"solution":false,"task":false},"execution":{"iopub.status.busy":"2022-06-25T12:59:23.877925Z","iopub.execute_input":"2022-06-25T12:59:23.878339Z","iopub.status.idle":"2022-06-25T12:59:24.132488Z","shell.execute_reply.started":"2022-06-25T12:59:23.878306Z","shell.execute_reply":"2022-06-25T12:59:24.131200Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"markdown","source":"#### Q7: Based on the learning curve, the performance of Sklearn's gradient boosting regressor is ______ our custom gradient boosting regressor?\n<b><div style=\"text-align: right\">[UNGRADED]</div></b>\n\n---\n\nSelect the best option.\n\n1. better than\n\n2. worse than\n\n3. same as\n\n\n__Task:__\nYou just need to put the correct option number on the variable `correct_option7`.\nIf your answer is same as, assign `correct_option7 = 3` and so on.\n","metadata":{"deletable":false,"id":"v9EZ-Z1MwsMF","nbgrader":{"cell_type":"markdown","checksum":"a58e9dc9c15fbfcffda3e438f3c78367","grade":false,"grade_id":"cell-147a5eaca6518f8e","locked":true,"schema_version":3,"solution":false,"task":false}}},{"cell_type":"code","source":"### Ex-11-Task-3\ncorrect_option7 = None\n### BEGIN SOLUTION\n# your code here\ncorrect_option7 = 1\n### END SOLUTION","metadata":{"deletable":false,"id":"46qOOEiywsMF","nbgrader":{"cell_type":"code","checksum":"e65fb4bbe66f280fc8c793b01d9d40ac","grade":false,"grade_id":"cell-0504746e027897c4","locked":false,"schema_version":3,"solution":true,"task":false},"tags":["Ex-11-Task-3"],"execution":{"iopub.status.busy":"2022-06-25T13:11:43.366337Z","iopub.execute_input":"2022-06-25T13:11:43.367223Z","iopub.status.idle":"2022-06-25T13:11:43.372068Z","shell.execute_reply.started":"2022-06-25T13:11:43.367175Z","shell.execute_reply":"2022-06-25T13:11:43.371220Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"assert correct_option7 is not None","metadata":{"deletable":false,"id":"_YBheC4rwsMH","nbgrader":{"cell_type":"code","checksum":"4efa499d42216f44ac571709cf0bd767","grade":true,"grade_id":"cell-4e6f62c6129f451d","locked":true,"points":0,"schema_version":3,"solution":false,"task":false},"tags":["Ex-11-Task-3"],"execution":{"iopub.status.busy":"2022-06-25T13:11:45.202190Z","iopub.execute_input":"2022-06-25T13:11:45.202982Z","iopub.status.idle":"2022-06-25T13:11:45.207252Z","shell.execute_reply.started":"2022-06-25T13:11:45.202947Z","shell.execute_reply":"2022-06-25T13:11:45.206347Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"markdown","source":"__Congratulation!!!!!!!!!!!!!__\n\n__You have completed the assignment__","metadata":{"deletable":false,"id":"O7Pq0ki3wsMJ","nbgrader":{"cell_type":"markdown","checksum":"fd0292bf7384c664f59fefd81ee78b88","grade":false,"grade_id":"cell-33338344697315bb","locked":true,"schema_version":3,"solution":false,"task":false}}}]}